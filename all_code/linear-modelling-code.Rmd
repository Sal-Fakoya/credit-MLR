---
title: "Credit Balance Prediction Analysis"
author: "Your Name"
date: "2023-12-01"
output: 
  pdf_document:
    latex_engine: xelatex
---

```{r setup, include=FALSE}
# Install required packages if not already installed
knitr::opts_chunk$set(echo = TRUE)

required_packages <- c("janitor", "dplyr", "ggplot2", "moments", "car", 
                      "caret", "MASS", "purrr", "knitr")
new_packages <- required_packages[!(required_packages %in% installed.packages()[,"Package"])]
if(length(new_packages)) install.packages(new_packages)

# Load libraries
library(janitor)
library(dplyr)
library(ggplot2)
library(moments)
library(car)
library(caret)
library(MASS)
library(purrr)
library(knitr)

# Set global options
options(scipen = 999)

```

# 1. Data Loading and Preprocessing

## 1.1 Load and Clean Data

```{r dataloading}
# Load data
data <- read.csv("./data/credit.csv") %>% 
  janitor::clean_names()

# Display basic info
cat("Dataset dimensions:", dim(data), "\n")
cat("Column names:", names(data), "\n")

```

## 1.2 Data Cleaning

```{r data-cleaning}
# Remove index column
data <- data[, -1]

# One-hot encoding for categorical variables
data$gender <- trimws(data$gender)
data$male <- ifelse(data$gender == "Male", yes = 1, no = 0)
data$is_student <- ifelse(data$student == "Yes", yes = 1, no = 0)
data$is_married <- ifelse(data$married == "Yes", yes = 1, no = 0)
data$african_american <- ifelse(data$ethnicity == "African American", yes = 1, no = 0)
data$asian <- ifelse(data$ethnicity == 'Asian', yes = 1, no = 0)

# Remove original categorical columns
data <- data %>% 
  dplyr::select(-c("gender", "student", "married", "ethnicity"))

# Display structure
str(data)
```

# 2. Exploratory Data Analysis (EDA)

## 2.1 Data Structure Overview

```{r data_structure}
cat("=== DATA STRUCTURE ===\n")
head(data) %>% kable()
summary(data) %>% kable()
```

#### Observation:

The dataset contains credit card information with balance as our target variable. Note that balance has a minimum of 0, suggesting we may need to address truncated normal distribution in our transformations.

## 2.2 Distribution Analysis

```{r distribution-analysis}
# Set up plotting area
par(mfrow = c(2, 3))

# Histograms with density curves for continuous variables
for(var in c("income", "limit", "rating", "age", "balance")) {
  hist(data[[var]], main = paste("Distribution of", var), 
       xlab = var, prob = TRUE, col = "lightblue")
  lines(density(data[[var]]), col = "red", lwd = 2)
  curve(dnorm(x, mean = mean(data[[var]]), sd = sd(data[[var]])), 
        add = TRUE, col = "blue", lty = 2)
  legend("topright", legend = c("Actual", "Normal"), 
         col = c("red", "blue"), lty = c(1, 2))
}
```

#### Observation from Histogram (ACTUAL) red curve:

-   Income: Right-skewed with long tail (red curve peaks left, extends right)

-   Limit: Right-skewed with long tail

-   Rating: Right-skewed with long tail

-   Age: Seems normal (red curve matches blue reasonably well). Though it has two peaks (take notice).

-   Balance: Right-skewed with long tail

Note: Plotted curves look truncated. Perhaps they may benefit from transformation. Here are other reasons for truncated normal curves in this dataset:

-   Income: Can't be negative, often clustered above minimum wage

-   Credit Limit: Always positive, often has minimum thresholds

-   Balance: Can be 0 but not negative (unless it's debt)

-   Rating: Often has minimum scores

## 2.3 Normality Assessment

```{r normality-assessment}
# Q-Q plots for normality
par(mfrow = c(2, 3))
for(var in c("income", "limit", "rating", "age", "balance")) {
  qqnorm(data[[var]], main = paste("Q-Q Plot for", var))
  qqline(data[[var]], col = "red")
}

# Skewness calculation
skew_values <- sapply(data[, c("income", "limit", "rating", "balance", "age")], skewness)
cat("=== SKEWNESS VALUES ===\n")
kable(data.frame(Variable = names(skew_values), Skewness = round(skew_values, 3)))

```

**Noted: Rule of thumb:**

-   \|skewness\| \< 0.5 : approximately symmetric (probably OK as-is)

-   0.5 \< \|skewness\| \< 1 : moderate skew (consider transformation)

-   \|skewness\| \> 1 : substantial skew (definitely transform)

# 3. Variable Transformations

## 3.1 Apply Transformations

```{r transformations}
# Apply transformations
data <- data %>% 
  mutate(
    log_income = log(income),
    log_limit = log(limit),
    log_rating = log(rating),
    log_balance = log(balance + 1),
    sqrt_balance = sqrt(balance)
  )

# Check transformed skewness
transformed_skew <- sapply(data[, c("log_income", "log_limit", "log_rating", "sqrt_balance", "age")], skewness)
cat("=== TRANSFORMED SKEWNESS VALUES ===\n")
kable(data.frame(Variable = names(transformed_skew), Skewness = round(transformed_skew, 3)))
```

**Observation:**

1.  Other variables look ok,

2.  Moderate skewness for log_limit: log-limit is now left-skewed

3.  Huge skewness for log_balance

## 3.2 Visualize Transformed Distributions

```{r visualize-transformed-distributions}
par(mfrow = c(2, 3))
for(var in c("log_income", "log_limit", "log_rating", "age", "sqrt_balance")) {
  hist(data[[var]], main = paste("Distribution of", var), 
       xlab = var, prob = TRUE, col = "lightgreen")
  lines(density(data[[var]]), col = "red", lwd = 2)
  curve(dnorm(x, mean = mean(data[[var]]), sd = sd(data[[var]])), 
        add = TRUE, col = "blue", lty = 2)
}
```

# 4. Initial Model Building

## 4.1 Fit Multiple Models

```{r initial-model_building}
# Prepare model data
model_data <- data

# Fit three different models
model_original <- lm(balance ~ log_income + log_limit + log_rating + 
                       cards + age + education + male + is_student + 
                       is_married + african_american + asian, data = model_data)

model_sqrt <- lm(sqrt_balance ~ log_income + log_limit + log_rating + 
                   cards + age + education + male + is_student + 
                   is_married + african_american + asian, data = model_data)

model_log <- lm(log_balance ~ log_income + log_limit + log_rating + 
                  cards + age + education + male + is_student + 
                  is_married + african_american + asian, data = model_data)

# Display model summaries
cat("=== ORIGINAL BALANCE MODEL ===\n")
summary(model_original)

cat("\n=== SQRT BALANCE MODEL ===\n")
summary(model_sqrt)

cat("\n=== LOG BALANCE MODEL ===\n")
summary(model_log)
```

## 4.2 Multicollinearity Check

```{r multicollinearity}
# VIF Analysis
cat("=== VARIANCE INFLATION FACTOR (VIF) ===\n")
vif_results <- data.frame(
  Original = vif(model_original),
  Sqrt = vif(model_sqrt),
  Log = vif(model_log)
)
kable(vif_results)
```

**Observation:** Credit limit and credit rating are linearly dependent. VIF: credit limit (76.031766), credit rating (79.324432). Some correlation there.

## 4.3 Address Multicollinearity

```{r address-multi-collinearity}

# Question 1: Is model better without credit limit?
model_original_noLimit <- lm(balance ~ log_income + log_rating + 
                       cards + age + education + male + is_student + 
                       is_married + african_american + asian, data = data)

model_sqrt_noLimit <- lm(sqrt_balance ~ log_income + log_rating + 
                   cards + age + education + male + is_student + 
                   is_married + african_american + asian, data = data)

model_log_noLimit <- lm(log_balance ~ log_income + log_rating + 
                  cards + age + education + male + is_student + 
                  is_married + african_american + asian, data = data)

# Compare models
cat("=== MODEL COMPARISON: WITH VS WITHOUT LIMIT ===\n")
cat("Original R-squared:", summary(model_original)$r.squared, 4)
cat("Without Limit R-squared:", round(summary(model_original_noLimit)$r.squared, 4), "\n")

```

**Conclusion**: Model seems better overall without credit limit. Moreover, credit limit is dependent on credit rating i.e Lenders use credit rating to determine credit limit. Note:

-   Higher-rated borrowers are less risky, so they get higher limits

-   Lower-rated borrowers are more risky, so they get lower limits to limit exposure

```{r update_models}
# Update models
model_original <- model_original_noLimit
model_log <- model_log_noLimit
model_sqrt <- model_sqrt_noLimit

# Check to see if our vif looks good: Multicollinearity
cat("=== UPDATED VIF (WITHOUT LIMIT) ===\n")
kable(data.frame(Variable = names(vif(model_original)), VIF = vif(model_original)))
```

# 5. Model Refinement

## 5.1 Boxcox Transformation

```{r transformation-boxcox}
# Step 6: Residual Diagnostics

# Check if sqrt_balance has non-positive values
summary(model_data$sqrt_balance)

# Check if sqrt_balance has non-positive values
min_value <- min(model_data$sqrt_balance)
if (min_value <= 0) {
  model_data$shifted_sqrt <- model_data$sqrt_balance - min_value + 0.001
  m_shifted <- lm(shifted_sqrt ~ log_income + is_student + log_rating, data = model_data)
  bc <- boxcox(m_shifted)
}

# Get optimal lambda
lambda <- bc$x[which.max(bc$y)]
cat("Optimal lambda:", lambda, "\n")

# Apply the Box-Cox transformation to the ORIGINAL balance variable
if (abs(lambda) < 0.001) {
  # If lambda ≈ 0, use log transformation
  model_data$bc_balance <- log(model_data$balance)
} else {
  # Standard Box-Cox transformation
  model_data$bc_balance <- (model_data$balance^lambda - 1) / lambda
}

# Fit the new model with Box-Cox transformed balance
m_bc <- lm(bc_balance ~ log_income + as.factor(is_student) + log_rating, data = model_data)
cat("=== BOX-COX TRANSFORMED MODEL ===\n")
summary(m_bc)
```

## 5.2 Alternative Transformation: Square Root Income

```{r alternative_transform}
# Try square root transformation for income

model_data <- model_data %>% mutate(income_sqrt = income^(1/2))

model_original <- lm(balance ~ cards + age + education + male + income_sqrt + african_american + is_married + asian + is_student + rating, data = model_data) 

cat("=== MODEL WITH SQRT INCOME ===\n")
summary(model_original)

# Diagnostic plots
par(mfrow = c(2,2))
plot(model_original, main = "Diagnostic Plots for Model with Sqrt Income")
```

**Conclusion for Residual Diagnostics:**

-   The Models from the Initial Model Selection violated Normality Assumption

-   I did a boxcox transformation which didn't change much

-   However, a sqrt transformation on income made the Residual vs Fitted Values plot more agreeable and satisfactory.

-   Hence I moved forward with: `model_original <- lm(balance ~ cards + age + education + male + income_sqrt + african_american + is_married + asian + is_student + rating, data = model_data)`

-   I performed more model selection on model_original vs sqrt_balance model using income_sqrt variable instead of income.

# 6. Advanced Model Selection

## 6.1 Stepwise Selection Functions

```{r stepwise_selection}
# Refined Model Selection - Part 1
# Step 5: Model Selection
# Model Selection Comparison for All Response Variables

# Function to run stepwise selection for a given response
run_stepwise_selection <- function(response_var, data) {
  # Create formula strings
  full_formula <- as.formula(paste(response_var, " ~ cards + age + education + male + income_sqrt + african_american + is_married + asian + is_student + rating"))
  empty_formula <- as.formula(paste(response_var, "~ 1"))
  
  # Fit models
  full_model <- lm(full_formula, data = data)
  empty_model <- lm(empty_formula, data = data)
  
  # Stepwise selection
  forward_aic <- stepAIC(empty_model, 
                         scope = list(upper = full_model, lower = ~1),
                         direction = "forward", trace = 0)
  
  forward_bic <- stepAIC(empty_model,
                         scope = list(upper = full_model, lower = ~1), 
                         direction = "forward", k = log(nrow(data)), trace = 0)
  
  backward_aic <- stepAIC(full_model, direction = "backward", trace = 0)
  backward_bic <- stepAIC(full_model, direction = "backward", 
                          k = log(nrow(data)), trace = 0)
  
  stepwise_aic <- stepAIC(empty_model,
                          scope = list(upper = full_model, lower = ~1),
                          direction = "both", trace = 0)
  
  stepwise_bic <- stepAIC(empty_model,
                          scope = list(upper = full_model, lower = ~1),
                          direction = "both", k = log(nrow(data)), trace = 0)
  
  # Return all models
  return(list(
    forward_aic = forward_aic,
    forward_bic = forward_bic,
    backward_aic = backward_aic,
    backward_bic = backward_bic,
    stepwise_aic = stepwise_aic,
    stepwise_bic = stepwise_bic
  ))
}

# Function to extract model metrics
get_model_metrics <- function(model, model_name, response_name) {
  model_summary <- summary(model)
  
  data.frame(
    Response = response_name,
    Method = model_name,
    AIC = round(AIC(model), 2),
    BIC = round(BIC(model), 2),
    R_squared = round(model_summary$r.squared, 4),
    Adj_R_squared = round(model_summary$adj.r.squared, 4),
    Num_Predictors = length(coef(model)) - 1,
    Predictors = paste(names(coef(model))[-1], collapse = ", "),
    stringsAsFactors = FALSE
  )
}

```

## 6.2 Comprehensive Model Comparison

```{r model_comparison}
# Run stepwise selection for all three response variables
balance_models <- run_stepwise_selection("balance", model_data)
log_balance_models <- run_stepwise_selection("log_balance", model_data)
sqrt_balance_models <- run_stepwise_selection("sqrt_balance", model_data)

# Create comparison table
comparison_table <- rbind(
  # Balance models
  get_model_metrics(balance_models$forward_aic, "Forward AIC", "balance"),
  get_model_metrics(balance_models$forward_bic, "Forward BIC", "balance"),
  get_model_metrics(balance_models$backward_aic, "Backward AIC", "balance"),
  get_model_metrics(balance_models$backward_bic, "Backward BIC", "balance"),
  get_model_metrics(balance_models$stepwise_aic, "Stepwise AIC", "balance"),
  get_model_metrics(balance_models$stepwise_bic, "Stepwise BIC", "balance"),
  
  # Log balance models
  get_model_metrics(log_balance_models$forward_aic, "Forward AIC", "log_balance"),
  get_model_metrics(log_balance_models$forward_bic, "Forward BIC", "log_balance"),
  get_model_metrics(log_balance_models$backward_aic, "Backward AIC", "log_balance"),
  get_model_metrics(log_balance_models$backward_bic, "Backward BIC", "log_balance"),
  get_model_metrics(log_balance_models$stepwise_aic, "Stepwise AIC", "log_balance"),
  get_model_metrics(log_balance_models$stepwise_bic, "Stepwise BIC", "log_balance"),
  
  # Sqrt balance models
  get_model_metrics(sqrt_balance_models$forward_aic, "Forward AIC", "sqrt_balance"),
  get_model_metrics(sqrt_balance_models$forward_bic, "Forward BIC", "sqrt_balance"),
  get_model_metrics(sqrt_balance_models$backward_aic, "Backward AIC", "sqrt_balance"),
  get_model_metrics(sqrt_balance_models$backward_bic, "Backward BIC", "sqrt_balance"),
  get_model_metrics(sqrt_balance_models$stepwise_aic, "Stepwise AIC", "sqrt_balance"),
  get_model_metrics(sqrt_balance_models$stepwise_bic, "Stepwise BIC", "sqrt_balance")
)

cat("=== COMPREHENSIVE MODEL SELECTION RESULTS ===\n")
kable(comparison_table %>% arrange(Response, AIC))

# Create a summary table showing best model for each response
best_models_summary <- comparison_table %>%
  group_by(Response) %>%
  slice(which.min(AIC)) %>%
  dplyr::select(Response, Method, AIC, BIC, R_squared, Adj_R_squared, Num_Predictors, Predictors)

cat("=== BEST MODELS BY RESPONSE ===\n")
kable(best_models_summary)
```

**Model Selection Conclusion:** We choose balance model why?

-   Variable transformation and Residual Diagnostics comparison showed balance model works is best

-   Original Model after VIF and Transformation: `model_original <- lm(balance ~ cards + age + education + male + income_sqrt + african_american + is_married + asian + is_student + rating, data = model_data)`

-   At this time, the balance model and sqrt_balance are both great options, however, Residual Diagnostics in next step show that model might be first choice due to having a more agreeable Residual vs Fitted Values plot

# 7. Model Validation

## 7.1 Cross-Validation Setup

```{r model_validation}
# Step 6: Model Diagnostics after Refined Model Selection:
model_data <- model_data %>% 
  dplyr::select(balance, log_balance, sqrt_balance, cards, age, education, male,
                income_sqrt, african_american, is_married, asian, 
                is_student, rating)

# 2nd Choice: sqrt_balance model: 
model_best2 <- lm(sqrt(balance) ~ rating + income_sqrt + is_student, data = model_data)
par(mfrow = c(2,2))
plot(model_best2, main = "sqrt_balance Model Diagnostics")

# 1st choice: balance model
model_best <- lm(balance ~ rating + income_sqrt + is_student + age + is_married, data = model_data)
par(mfrow = c(2,2))
plot(model_best, main = "balance Model Diagnostics")
```

**Residual Diagnostics**: balance model is more agreeable

## 7.2 Cross-Validation

```{r cross-validate}
# Step 7: Cross-Validation for Refined Model Selection: K-Fold Cross-Validation
set.seed(12345678)

# CV to choose the best one
K <- 10
N <- nrow(model_data)
validSetSplits <-sample((1:N)%%K + 1)
RMSE_best <- numeric(K)
RMSE_sqrt <- numeric(K)

for (k in 1:K) {
  validSet <- model_data[validSetSplits == k, ]
  trainSet <- model_data[validSetSplits != k, ]
  
  # Model 1: Model_best 1 
  model_best <- lm(balance ~ rating + income_sqrt + is_student + age + is_married, data = trainSet)
  pred1 <- predict(model_best, newdata = validSet)
  RMSE_best[k] <- sqrt(mean((validSet$balance- pred1)^2))
  
  # Model 2: Model Best 2: - CONVERT BACK to dollars
  model_sqrt <- lm(sqrt(balance) ~ rating + income_sqrt + is_student, data = trainSet)
  pred2_sqrt <- predict(model_sqrt, newdata = validSet)
  pred2_dollars <- pred2_sqrt^2  # Convert back to original scale
  RMSE_sqrt[k] <- sqrt(mean((validSet$balance - pred2_dollars)^2))
}

# Now compare properly
cat("Balance Model RMSE:", mean(RMSE_best), "\n")
cat("Sqrt Balance Model RMSE:", mean(RMSE_sqrt), "\n") 

# Calculate improvement percentage
improvement <- ((mean(RMSE_sqrt) - mean(RMSE_best)) / mean(RMSE_sqrt)) * 100

# Final model selection based on CV performance
final_model <- lm(balance ~ rating + income_sqrt + is_student + age + is_married, 
                  data = model_data)

cat("=== FINAL MODEL SELECTED ===\n")
cat("Based on cross-validation, model_best has superior performance:\n")
cat("RMSE:", round(mean(RMSE_best), 2), "vs", round(mean(RMSE_sqrt), 2), 
    "(", round(improvement, 1), "% improvement)\n")
cat("Formula: balance ~ rating + sqrt(income) + is_student + age + is_married\n")

cat("\n=== FINAL MODEL SUMMARY ===\n")
summary(final_model)
```

**Conclusion: Refined Model Selection:** Due to having lower RMSE, the 1st choice Model is the best refined model to move forward with.

# 8. Outlier Analysis

## 8.1 Detect Influential Observations

```{r outlier_analysis}
# Step 8: Outlier detection: 
# Question: Is the Model better with or without Outliers?
# Outlier detection

# Methods to detect outliers:
# 1. Studentized Residuals (for outliers in response variable)
# 2. High leverage (for outliers in predictor variable)
# 3. High Influential Observations (extreme values in both response and predictors)

model_best <- final_model
# Standardized residuals (z-scores of residuals)
model_data$std_resid <- rstandard(model_best)

# Cook's distance (influence)
model_data$cooks <- cooks.distance(model_best)

# Leverage
model_data$leverage <- hatvalues(model_best)

n <- nrow(model_data)
p <- length(coef(model_best)) - 1

outliers <- which(abs(model_data$std_resid) > 3)
high_cooks <- which(model_data$cooks > (4 / n))
high_leverage <- which(model_data$leverage > (2 * (p + 1) / n))

cat("Outliers (|standardized residual| > 3):", length(outliers), "\n")
cat("High Cook's Distance (> 4/n):", length(high_cooks), "\n")
cat("High Leverage (> 2*(p+1)/n):", length(high_leverage), "\n")

# Since Cook's distance is used to measure Influential Observations, let's clean data using cook's distance
clean_data <- model_data[-unique(c(high_cooks)), ]

model_best_clean <- lm(balance ~ rating + income_sqrt + is_student + age + is_married, data = clean_data)

cat("=== MODEL WITH OUTLIERS REMOVED ===\n")
summary(model_best_clean)
cat("Removed", nrow(model_data) - nrow(clean_data), "observations. Now we have", nrow(clean_data), "observations.\n")

```

## 8.2 Compare Models with/without Outliers

```{r comparing_models_and_outliers}
# Question: Is final_model better with or without outliers?
# Let's do Cross-validation:

set.seed(12345678)
K <- 10
N <- nrow(clean_data)
validSetSplits <-sample((1:N)%%K + 1)
clean_RMSE_best <- numeric(K)

for (k in 1:K) {
  validSet <- clean_data[validSetSplits == k, ]
  trainSet <- clean_data[validSetSplits != k, ]
  
  model_best <- lm(balance ~ rating + income_sqrt + is_student + age + is_married, data = trainSet)
  pred1 <- predict(model_best, newdata = validSet)
  clean_RMSE_best[k] <- sqrt(mean((validSet$balance- pred1)^2))
}

cat("Model without outliers RMSE:", mean(clean_RMSE_best), "\n")
cat("Model with outliers RMSE:", mean(RMSE_best), "\n")

improvement <- ((mean(RMSE_best) - mean(clean_RMSE_best)) / mean(RMSE_best)) * 100
cat("Improvement percentage:", round(improvement, 1), "%\n")

```

## 8.3 Test without is_married Variable

```{r is_married_needed}
# without is_married variable, is model better??
set.seed(12345678)

K <- 10
N <- nrow(clean_data)
validSetSplits <-sample((1:N)%%K + 1)
clean_RMSE_best <- numeric(K)

for (k in 1:K) {
  validSet <- clean_data[validSetSplits == k, ]
  trainSet <- clean_data[validSetSplits != k, ]
  
  model_best <- lm(balance ~ rating + income_sqrt + is_student + age, data = trainSet)
  pred1 <- predict(model_best, newdata = validSet)
  clean_RMSE_best[k] <- sqrt(mean((validSet$balance- pred1)^2))
}

cat("Simpler model (without is_married) RMSE:", mean(clean_RMSE_best), "\n")
```

## 8.4 Comprehensive Model Comparison

```{r comprehensive-comparison}

# Step 9: Compare final Models:
# List to store results
model_list <- list(
  list(name = "With Outliers, With is_married", formula = balance ~ rating + income_sqrt + is_student + age + is_married, data = model_data),
  list(name = "Without Outliers, With is_married", formula = balance ~ rating + income_sqrt + is_student + age + is_married, data = clean_data),
  list(name = "Without Outliers, Without is_married", formula = balance ~ rating + income_sqrt + is_student + age, data = clean_data),
  list(name = "With Outliers, Without is_married", formula = balance ~ rating + income_sqrt + is_student + age, data = model_data)
)

# Function for K-fold CV RMSE
cv_rmse <- function(formula, data, K=10, seed=123){
  set.seed(seed)
  N <- nrow(data)
  folds <- sample((1:N) %% K + 1)
  rmse_values <- numeric(K)
  
  for(k in 1:K){
    train <- data[folds != k, ]
    valid <- data[folds == k, ]
    model <- lm(formula, data = train)
    preds <- predict(model, newdata = valid)
    rmse_values[k] <- sqrt(mean((valid[[as.character(formula[[2]])]] - preds)^2))
  }
  
  mean(rmse_values)
}

# Initialize dataframe
model_summary <- data.frame(
  Model = character(),
  Outliers_Removed = logical(),
  Includes_is_married = logical(),
  CV_RMSE = numeric(),
  Residual_SE = numeric(),
  Adjusted_R2 = numeric(),
  stringsAsFactors = FALSE
)

# Loop through each model and compute metrics
for(m in model_list){
  fit <- lm(m$formula, data = m$data)
  cv <- cv_rmse(m$formula, m$data)
  
  model_summary <- rbind(model_summary, data.frame(
    Model = m$name,
    Outliers_Removed = ifelse(grepl("Without Outliers", m$name), TRUE, FALSE),
    Includes_is_married = ifelse(grepl("Without is_married", m$name), FALSE, TRUE),
    CV_RMSE = round(cv, 2),
    Residual_SE = round(summary(fit)$sigma, 2),
    Adjusted_R2 = round(summary(fit)$adj.r.squared, 4)
  ))
}

cat("=== FINAL MODEL COMPARISON ===\n")
kable(model_summary)

```

**Conclusion:**

-   is_married column is negligible. The Adjusted R\^2 without is_married is about the same as with is_married column in the model.

-   is_married column is not statistically significant in the with Outliers model at the 5% level. Hence there is no strong evidence of its effect on balance.

-   The best model is the one Without Outliers and Without is_married column due to having the lowest validation RMSE from Cross-Validation

# 9. Final Model Selection

## 9.1 Optimal Model

```{r optimal_selection}
# Step 10: Display and Explain Best Model:

# Calculate all metrics without hard-coding
best_final_model <- lm(balance ~ rating + income_sqrt + is_student + age, 
                       data = clean_data)

cat("=== FINAL OPTIMAL MODEL ===\n")
summary(best_final_model)

# Re-run CV to get the actual RMSE programmatically
set.seed(12345678)
K <- 10
N <- nrow(clean_data)
validSetSplits <- sample((1:N) %% K + 1)
final_rmse_values <- numeric(K)

for (k in 1:K) {
  validSet <- clean_data[validSetSplits == k, ]
  trainSet <- clean_data[validSetSplits != k, ]
  
  model_cv <- lm(balance ~ rating + income_sqrt + is_student + age, data = trainSet)
  pred <- predict(model_cv, newdata = validSet)
  final_rmse_values[k] <- sqrt(mean((validSet$balance - pred)^2))
}

final_cv_rmse <- mean(final_rmse_values)
final_cv_se <- sd(final_rmse_values) / sqrt(K)

cat("=== FINAL OPTIMAL MODEL CONFIRMED ===\n")
cat("Model: balance ~ rating + income_sqrt + is_student + age\n")
cat("Dataset:", nrow(clean_data), "observations (", nrow(model_data) - nrow(clean_data), "influential points removed)\n")
cat("Cross-Validation Performance:\n")
cat("  RMSE:", round(final_cv_rmse, 2), "±", round(final_cv_se, 2), "\n")
cat("  R²:", round(summary(best_final_model)$adj.r.squared, 4), "\n")
cat("  Residual SE:", round(summary(best_final_model)$sigma, 2), "\n")

cat("\nKey Insights:\n")
cat("• Credit rating is the strongest predictor (coefficient:", round(coef(best_final_model)["rating"], 2), ")\n")
cat("• Student status increases balances by $", round(coef(best_final_model)["is_student"], 2), "\n") 
cat("• Square-root income transformation works best\n")
cat("• Age has a small but significant effect (coefficient:", round(coef(best_final_model)["age"], 2), ")\n")

# Show coefficient significance
cat("\nStatistical Significance:\n")
coef_summary <- summary(best_final_model)$coefficients
for (predictor in rownames(coef_summary)[-1]) {  # Skip intercept
  p_value <- coef_summary[predictor, 4]
  significance <- ifelse(p_value < 0.001, "***", 
                         ifelse(p_value < 0.01, "**",
                                ifelse(p_value < 0.05, "*", "not significant")))
  cat("•", predictor, ":", significance, "(p =", round(p_value, 4), ")\n")
}

```

## 9.2 Model Diagnostics

```{r model_diagnostics}
# Comprehensive diagnostic plots
par(mfrow = c(2, 2))
plot(best_final_model, main = "Final Model Diagnostic Plots")

# Residual analysis
par(mfrow = c(2, 2))
plot(clean_data$rating, residuals(best_final_model), 
     xlab = "Credit Rating", ylab = "Residuals",
     main = "Residuals vs Rating")
plot(clean_data$income_sqrt, residuals(best_final_model),
     xlab = "Square Root Income", ylab = "Residuals",
     main = "Residuals vs Income")
plot(factor(clean_data$is_student), residuals(best_final_model),
     xlab = "Student Status", ylab = "Residuals",
     main = "Residuals vs Student Status")
plot(clean_data$age, residuals(best_final_model),
     xlab = "Age", ylab = "Residuals",
     main = "Residuals vs Age")
```

# 10. Prediction and Confidence Interval

```{r model_prediction}
# Step 10: Prediction with Confidence Intervals
cat("=== PREDICTION WITH NEW OBSERVATIONS ===\n")

# Example prediction
new_observation <- data.frame(
  rating = 500,
  income_sqrt = sqrt(50),  # Convert income to sqrt scale
  is_student = 1,
  age = 25
)

# Step 11: Prediction using new observation on a 95% Prediction Interval
prediction <- predict(best_final_model, newdata = new_observation, 
                      interval = "prediction", level = 0.95)

cat("Prediction for new observation:\n")
cat("Expected balance: $", round(prediction[1], 2), "\n")
cat("95% Prediction interval: [$", round(prediction[2], 2), ", $", 
    round(prediction[3], 2), "]\n")

# Interpretation
cat("\nBusiness Interpretation:\n")
cat("A student with credit rating 500, income $50k, and age 25 would have:\n")
cat("• Predicted balance: $", round(prediction[1], 2), "\n")
cat("• 95% chance actual balance between: $", round(prediction[2], 2), 
    "and $", round(prediction[3], 2), "\n")
```

## 10.2 Model Interpretation

```{r model_interpretation}
# Coefficient interpretation
coef_summary <- summary(best_final_model)$coefficients

cat("=== MODEL INTERPRETATION ===\n")
cat("Final Model: balance =", round(coef_summary[1,1], 2), 
    "+", round(coef_summary[2,1], 2), "* rating +",
    round(coef_summary[3,1], 2), "* sqrt(income) +",
    round(coef_summary[4,1], 2), "* student +",
    round(coef_summary[5,1], 2), "* age\n\n")

cat("Key Insights:\n")
cat("1. Credit Rating: Each 1-point increase → $", round(coef_summary[2,1], 2), 
    "higher balance (p =", round(coef_summary[2,4], 4), ")\n")
cat("2. Student Status: Students have $", round(coef_summary[4,1], 2), 
    "higher balances (p =", round(coef_summary[4,4], 4), ")\n")
cat("3. Age: Each year older → $", round(coef_summary[5,1], 2), 
    "lower balance (p =", round(coef_summary[5,4], 4), ")\n")
cat("4. Income: Square root transformation provides best fit\n")

cat("\nModel Performance:\n")
cat("R-squared:", round(summary(best_final_model)$r.squared, 4), "\n")
cat("Adjusted R-squared:", round(summary(best_final_model)$adj.r.squared, 4), "\n")
cat("Residual Standard Error: $", round(summary(best_final_model)$sigma, 2), "\n")

```

# 11. Conclusion

## 11.1 Summary of Findings

```{r summary_model_findings, echo=FALSE}
cat("=== PROJECT SUMMARY ===\n\n")

cat("
After comprehensive analysis, the optimal model for predicting credit card balances is:

    Balance = -175.05 + 3.91*Rating - 108.34*sqrt(Income) + 420.30*Student - 0.93*Age

Key Findings:

• Credit rating is the strongest predictor of balance
• Student status significantly increases credit card balances
• Age has a small but statistically significant negative effect
• Square root transformation of income provided the best fit
• Removal of influential observations improved model robustness
• Final model explains 95.3% of variance in credit card balances
• Cross-validation RMSE: 95.42, indicating good predictive accuracy
")

```
